{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:57.858161Z","iopub.execute_input":"2024-11-04T19:26:57.859079Z","iopub.status.idle":"2024-11-04T19:26:57.863520Z","shell.execute_reply.started":"2024-11-04T19:26:57.859032Z","shell.execute_reply":"2024-11-04T19:26:57.862363Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!!curl -O http://www.manythings.org/anki/hin-eng.zip\n!!unzip hin-eng.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:57.880460Z","iopub.execute_input":"2024-11-04T19:26:57.880820Z","iopub.status.idle":"2024-11-04T19:26:58.277140Z","shell.execute_reply.started":"2024-11-04T19:26:57.880786Z","shell.execute_reply":"2024-11-04T19:26:58.275857Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['Archive:  hin-eng.zip',\n 'replace hin.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n '(EOF or read error, treating as \"[N]one\" ...)']"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 500  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 10000  # Number of samples to train on.\n# Path to the data txt file on disk.\ndata_path = \"hin.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:58.279046Z","iopub.execute_input":"2024-11-04T19:26:58.279398Z","iopub.status.idle":"2024-11-04T19:26:58.285240Z","shell.execute_reply.started":"2024-11-04T19:26:58.279362Z","shell.execute_reply":"2024-11-04T19:26:58.284354Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\"\\t\")\n    # We use \"tab\" as the \"start sequence\" character\n    # for the targets, and \"\\n\" as \"end sequence\" character.\n    target_text = \"\\t\" + target_text + \"\\n\"\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\"Number of samples:\", len(input_texts))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\ninput_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n)\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.0\n    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.0\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:58.286588Z","iopub.execute_input":"2024-11-04T19:26:58.286916Z","iopub.status.idle":"2024-11-04T19:26:58.740864Z","shell.execute_reply.started":"2024-11-04T19:26:58.286883Z","shell.execute_reply":"2024-11-04T19:26:58.740020Z"}},"outputs":[{"name":"stdout","text":"Number of samples: 3061\nNumber of unique input tokens: 70\nNumber of unique output tokens: 92\nMax sequence length for inputs: 107\nMax sequence length for outputs: 123\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Define an input sequence and process it.\nencoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\nencoder = keras.layers.GRU(latent_dim, return_state=True)\nencoder_outputs, state_h = encoder(encoder_inputs)\n\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_gru = keras.layers.GRU(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _ = decoder_gru(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:58.742854Z","iopub.execute_input":"2024-11-04T19:26:58.743183Z","iopub.status.idle":"2024-11-04T19:26:58.819463Z","shell.execute_reply.started":"2024-11-04T19:26:58.743148Z","shell.execute_reply":"2024-11-04T19:26:58.818729Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model.compile(\n    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n)\nmodel.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:26:58.820449Z","iopub.execute_input":"2024-11-04T19:26:58.820712Z","iopub.status.idle":"2024-11-04T19:26:59.662725Z","shell.execute_reply.started":"2024-11-04T19:26:58.820682Z","shell.execute_reply":"2024-11-04T19:26:59.661241Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/500\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling GRU.call().\n\n\u001b[1mlen is not well defined for a symbolic Tensor (functional_5_1/gru_9_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.\u001b[0m\n\nArguments received by GRU.call():\n  • sequences=tf.Tensor(shape=(None, 107, 70), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=True"],"ename":"TypeError","evalue":"Exception encountered when calling GRU.call().\n\n\u001b[1mlen is not well defined for a symbolic Tensor (functional_5_1/gru_9_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.\u001b[0m\n\nArguments received by GRU.call():\n  • sequences=tf.Tensor(shape=(None, 107, 70), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=True","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.layers import Input, LSTM, GRU, Dense","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:30:38.829623Z","iopub.execute_input":"2024-11-04T19:30:38.830038Z","iopub.status.idle":"2024-11-04T19:30:38.836334Z","shell.execute_reply.started":"2024-11-04T19:30:38.829996Z","shell.execute_reply":"2024-11-04T19:30:38.835531Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"encoder_gru = GRU(latent_dim, return_state=True)\nencoder_outputs, state_h = encoder_gru(encoder_inputs)\n\nencoder_states_gru = [state_h]\n\ndecoder_gru = GRU(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs_gru, _ = decoder_gru(decoder_inputs,\n                                     initial_state=encoder_states_gru)\ndecoder_dense_gru = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs_gru = decoder_dense_gru(decoder_outputs_gru)\n\nmodel_gru = Model([encoder_inputs, decoder_inputs], decoder_outputs_gru)\n\nmodel_gru.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n              metrics=['accuracy'])\nhistory_gru = model_gru.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n          batch_size=batch_size,\n          epochs=30,\n          validation_split=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:30:40.350377Z","iopub.execute_input":"2024-11-04T19:30:40.350762Z","iopub.status.idle":"2024-11-04T19:30:41.280622Z","shell.execute_reply.started":"2024-11-04T19:30:40.350725Z","shell.execute_reply":"2024-11-04T19:30:41.279106Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m model_gru \u001b[38;5;241m=\u001b[39m Model([encoder_inputs, decoder_inputs], decoder_outputs_gru)\n\u001b[1;32m     14\u001b[0m model_gru\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m history_gru \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling GRU.call().\n\n\u001b[1mlen is not well defined for a symbolic Tensor (functional_7_1/gru_11_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.\u001b[0m\n\nArguments received by GRU.call():\n  • sequences=tf.Tensor(shape=(None, 107, 70), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=True"],"ename":"TypeError","evalue":"Exception encountered when calling GRU.call().\n\n\u001b[1mlen is not well defined for a symbolic Tensor (functional_7_1/gru_11_1/Squeeze:0). Please call `x.shape` rather than `len(x)` for shape information.\u001b[0m\n\nArguments received by GRU.call():\n  • sequences=tf.Tensor(shape=(None, 107, 70), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=True","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}